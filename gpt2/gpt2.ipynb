{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75zHHQZrkHR1"
   },
   "source": [
    "# gpt-2-simple\n",
    "\n",
    "package from: https://github.com/minimaxir/gpt-2-simple\n",
    "\n",
    "*note: this notebook was created and run on a colab pro account.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQcvWXeCv-5-",
    "outputId": "8d4fa07b-a68d-46ed-e79d-343b45925221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "\u001b[K     |████████████████████████████████| 497.5 MB 23 kB/s \n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 51.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 55.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 462 kB 64.7 MB/s \n",
      "\u001b[?25h  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# install gpt-2-simple; requires tf version 1.x\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvqxJleXgGE5",
    "outputId": "a035b223-a082-41ec-9799-f5dc62ac3aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 124M model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 663Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 5.14Mit/s]\n",
      "Fetching hparams.json: 1.05Mit [00:00, 572Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:11, 44.1Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 427Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 7.74Mit/s]\n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 6.82Mit/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading small gpt2 model (124M)\n",
    "\n",
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MB-_tEFggWal",
    "outputId": "659dc13a-c388-49a2-c7d3-763a17a94f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMBJvhH5gXDk"
   },
   "outputs": [],
   "source": [
    "file_name = \"wsmerwin_total.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjoRhV1vhVvv",
    "outputId": "5c9eac6a-c1f9-451b-d47f-ccb6af8ae581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 245.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 26742 tokens\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 | 18.93] loss=1.49 avg=1.49\n",
      "[20 | 33.09] loss=1.39 avg=1.44\n",
      "[30 | 47.25] loss=1.32 avg=1.40\n",
      "[40 | 61.40] loss=1.15 avg=1.34\n",
      "[50 | 75.55] loss=0.98 avg=1.26\n",
      "[60 | 89.70] loss=0.58 avg=1.15\n",
      "[70 | 103.85] loss=0.40 avg=1.04\n",
      "[80 | 118.01] loss=0.22 avg=0.93\n",
      "[90 | 132.17] loss=0.24 avg=0.85\n",
      "[100 | 146.32] loss=0.07 avg=0.77\n",
      "[110 | 160.47] loss=0.06 avg=0.70\n",
      "[120 | 174.63] loss=0.05 avg=0.64\n",
      "[130 | 188.78] loss=0.03 avg=0.59\n",
      "[140 | 202.95] loss=0.04 avg=0.55\n",
      "[150 | 217.09] loss=0.03 avg=0.51\n",
      "[160 | 231.25] loss=0.03 avg=0.48\n",
      "[170 | 245.41] loss=0.03 avg=0.45\n",
      "[180 | 259.56] loss=0.02 avg=0.43\n",
      "[190 | 273.73] loss=0.02 avg=0.40\n",
      "[200 | 287.89] loss=0.02 avg=0.38\n",
      "Saving checkpoint/run1/model-200\n"
     ]
    }
   ],
   "source": [
    "# finetune model with w.s. merwin text\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=200,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=200,\n",
    "              save_every=200\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KWGLWiQek7z"
   },
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "\n",
    "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMoqZ1PloAEQ",
    "outputId": "fa2bb87f-e11a-40b3-b387-4b5c4afd18cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it could be made to stop.”\n",
      "====================\n",
      "and the sunlight tracking down\n",
      "====================\n",
      "whether it be at home or away the blood runs in my eyes\n",
      "====================\n",
      "pale in the daylight\n",
      "====================\n",
      "looking up step by step into\n",
      "====================\n",
      "within feet\n",
      "====================\n",
      "red undercurrent of consciences\n",
      "====================\n",
      "Of numbers\n",
      "====================\n",
      "spoke with unbroken knowledge\n",
      "====================\n",
      "and who might have been the brother of the late\n",
      "====================\n",
      "\n",
      "====================\n",
      "Among the pile of bricks by the bridge where the water ran\n",
      "====================\n",
      "and the lingering\n",
      "====================\n",
      "that they might be filled with company\n",
      "====================\n",
      "\n",
      "====================\n",
      "and its echo\n",
      "====================\n",
      "which I know will say\n",
      "====================\n",
      "with no acquaintance or understanding\n",
      "====================\n",
      "On the road I see men milling about with no company\n",
      "====================\n",
      "Now\n",
      "====================\n",
      "of the camelor to the fall\n",
      "====================\n",
      "in the same time zone\n",
      "====================\n",
      "Which are the ways of the dead\n",
      "====================\n",
      "in the last days of the world\n",
      "====================\n",
      "at the foot of the wall\n",
      "====================\n",
      "after I had told them\n",
      "====================\n",
      "staring from the end of the world\n",
      "====================\n",
      "And he who sees it will say\n",
      "====================\n",
      "and be sustained\n",
      "====================\n",
      "and if possible with kindness</|endoftext|>\n",
      "<|startoftext|>And grant her the love of one woman\n",
      "====================\n",
      "in the dark that summer when the light turns green and there is nothing but darkness\n",
      "====================\n",
      "as though they had never happened\n",
      "====================\n",
      "and a little bit later\n",
      "====================\n",
      "who have fallen in and become the poorest of the poor\n",
      "====================\n",
      "Dragging water bottles\n",
      "====================\n",
      "Is a language\n",
      "====================\n",
      "Pain and suffering\n",
      "====================\n",
      "in a parked cab by the sealed wall\n",
      "====================\n",
      "They play a part in the whole process\n",
      "====================\n",
      "and by the hour in the morning they make up for with them\n",
      "====================\n",
      "Now be brief; tomorrow will be long\n",
      "====================\n",
      "but they said\n",
      "====================\n",
      "And those who do not\n",
      "====================\n",
      "\n",
      "====================\n",
      "The small boat might have carried him\n",
      "====================\n",
      "whatever we had\n",
      "====================\n",
      "which were painted black and gold and the notes of lightning\n",
      "====================\n",
      "of water they are a shade too small\n",
      "====================\n",
      "staring from the end of the world\n",
      "====================\n",
      "staring from the end of the world\n",
      "====================\n",
      "and whose character I could not tell. But\n",
      "====================\n",
      "all these years I have heard\n",
      "====================\n",
      "and the others nodding along\n",
      "====================\n",
      "and who spoke with a kind voice\n",
      "====================\n",
      "It is the sound of the whole body\n",
      "====================\n",
      "They said thank you but nothing has happened\n",
      "====================\n",
      "\n",
      "====================\n",
      "Have no names\n",
      "====================\n",
      "And the days hang medals between us\n",
      "====================\n",
      "which I have studied\n",
      "====================\n",
      "And grant his charity\n",
      "====================\n",
      "not the whole song but a brief phrase of it\n",
      "====================\n",
      "\n",
      "====================\n",
      "which the tongue had taught me\n",
      "====================\n",
      "in a parked cab by the sealed wall\n",
      "====================\n",
      "<|startoftext|>I push them along\n",
      "====================\n",
      "in the autumn of the same year\n",
      "====================\n",
      "with the words running along them\n",
      "====================\n",
      "ASSURE I have known you\n",
      "====================\n",
      "and the bells stop\n",
      "====================\n",
      "with its clouds of smoke rising from the jets of the fire engine\n",
      "====================\n",
      "in the same month\n",
      "====================\n",
      "he started out well\n",
      "====================\n",
      "Oh pile of white shirts who is coming\n",
      "====================\n",
      "It is the sound of our voices\n",
      "====================\n",
      "being patient\n",
      "====================\n",
      "whether they remember it or not\n",
      "====================\n",
      "\n",
      "====================\n",
      "pale in the daylight\n",
      "====================\n",
      "There and back again\n",
      "====================\n",
      "To the small of my back that held\n",
      "====================\n",
      "partly for the faith in you\n",
      "====================\n",
      "before I could say a word.\n",
      "====================\n",
      "Will the wind hear me\n",
      "====================\n",
      "that they would hear again by way of another\n",
      "====================\n",
      "to the sound of their voices\n",
      "====================\n",
      "then he spoke to me\n",
      "====================\n",
      "Now I know\n",
      "====================\n",
      "Others lie.”\n",
      "====================\n",
      "with no acquaintance\n",
      "====================\n",
      "as though he might ring a bell\n",
      "====================\n",
      "each with its lime-washed church by the baked square\n",
      "====================\n",
      "with its wellsprings full of wellsorted water\n",
      "====================\n",
      "then I will cease\n",
      "====================\n",
      "Set your eyes to the sky\n",
      "====================\n",
      "unheard by\n",
      "====================\n",
      "I think I may have made up my mind\n",
      "====================\n",
      "with\n",
      "====================\n",
      "Identity you with the curves of shadow\n",
      "====================\n",
      "That it should happen before it is too late\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# test generating text\n",
    "\n",
    "gpt2.generate(sess,\n",
    "              length=200,\n",
    "              temperature=0.8,\n",
    "              prefix='<|startoftext|>',\n",
    "              truncate='<|endoftext|>',\n",
    "              include_prefix=False,\n",
    "              nsamples=100,\n",
    "              batch_size=20\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u45EtVUsjM8R"
   },
   "outputs": [],
   "source": [
    "# bulk generate text and save as .txt files\n",
    "\n",
    "num_files = 10\n",
    "\n",
    "for _ in range(num_files):\n",
    "  gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
    "\n",
    "  gpt2.generate_to_file(sess,\n",
    "                        destination_path=gen_file,\n",
    "                        length=200,\n",
    "                        temperature=1.0,\n",
    "                        top_p=0.9,\n",
    "                        prefix='<|startoftext|>',\n",
    "                        truncate='<|endoftext|>',\n",
    "                        include_prefix=False,\n",
    "                        nsamples=1000,\n",
    "                        batch_size=20\n",
    "                        )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pfch_final project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
